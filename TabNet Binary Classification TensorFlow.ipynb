{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# importing the libraries for data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Importing the libraries for the model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Importing the libraries for the evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Importing additional libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gzip\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                             Mr. Owen Harris Braund   \n",
      "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
      "2         1       3                              Miss. Laina Heikkinen   \n",
      "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
      "4         0       3                            Mr. William Henry Allen   \n",
      "\n",
      "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
      "0    male  22.0                        1                        0   7.2500  \n",
      "1  female  38.0                        1                        0  71.2833  \n",
      "2  female  26.0                        0                        0   7.9250  \n",
      "3  female  35.0                        1                        0  53.1000  \n",
      "4    male  35.0                        0                        0   8.0500  \n"
     ]
    }
   ],
   "source": [
    "# Download titanic dataset\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "\n",
    "# Define the file paths\n",
    "data_path = Path('data')\n",
    "data_file = data_path / 'titanic.csv'\n",
    "\n",
    "# Store the data in the data folder\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "# Download the data\n",
    "if not os.path.exists(data_file):\n",
    "    wget.download(url, data_file.as_posix())\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(data_file)\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 887 entries, 0 to 886\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Survived                 887 non-null    int64  \n",
      " 1   Pclass                   887 non-null    int64  \n",
      " 2   Name                     887 non-null    object \n",
      " 3   Sex                      887 non-null    object \n",
      " 4   Age                      887 non-null    float64\n",
      " 5   Siblings/Spouses Aboard  887 non-null    int64  \n",
      " 6   Parents/Children Aboard  887 non-null    int64  \n",
      " 7   Fare                     887 non-null    float64\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived                   0\n",
      "Pclass                     0\n",
      "Sex                        0\n",
      "Age                        0\n",
      "Siblings/Spouses Aboard    0\n",
      "Parents/Children Aboard    0\n",
      "Fare                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the columns that are not required\n",
    "data.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "# Check the missing values in the data\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "0    545\n",
      "1    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check survived column\n",
    "print(data['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target and features\n",
    "target = 'Survived'\n",
    "features = data.columns.drop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(709, 6) (178, 6)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the train and test data\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "0    434\n",
      "1    275\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution in the target\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "3    394\n",
      "1    170\n",
      "2    145\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in Pclass\n",
    "print(X_train['Pclass'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_columns = ['Sex', 'Pclass']  # Include both 'Sex' and 'Pclass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder for the categorical columns using LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoders = {}\n",
    "for cat_col in X_train.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[cat_col] = le.fit_transform(X_train[cat_col])\n",
    "    X_test[cat_col] = le.transform(X_test[cat_col])\n",
    "    label_encoders[cat_col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "730       2    1  23.0                        0                        0   \n",
       "390       3    1  28.0                        2                        0   \n",
       "118       3    0   2.0                        4                        2   \n",
       "440       2    0  28.0                        0                        0   \n",
       "309       1    0  18.0                        2                        2   \n",
       "\n",
       "        Fare  \n",
       "730   13.000  \n",
       "390    7.925  \n",
       "118   31.275  \n",
       "440   13.000  \n",
       "309  262.375  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows of the data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sex': LabelEncoder()}\n"
     ]
    }
   ],
   "source": [
    "# check label encoders\n",
    "print(label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model/label_encoders.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the label encoders using joblib\n",
    "joblib.dump(label_encoders, 'Model/label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standar scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.449010</td>\n",
       "      <td>-0.470388</td>\n",
       "      <td>-0.475009</td>\n",
       "      <td>-0.388597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.094153</td>\n",
       "      <td>1.275711</td>\n",
       "      <td>-0.475009</td>\n",
       "      <td>-0.484577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.939405</td>\n",
       "      <td>3.021810</td>\n",
       "      <td>1.992254</td>\n",
       "      <td>-0.042975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.094153</td>\n",
       "      <td>-0.470388</td>\n",
       "      <td>-0.475009</td>\n",
       "      <td>-0.388597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.803866</td>\n",
       "      <td>1.275711</td>\n",
       "      <td>1.992254</td>\n",
       "      <td>4.327664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
       "730       2    1 -0.449010                -0.470388                -0.475009   \n",
       "390       3    1 -0.094153                 1.275711                -0.475009   \n",
       "118       3    0 -1.939405                 3.021810                 1.992254   \n",
       "440       2    0 -0.094153                -0.470388                -0.475009   \n",
       "309       1    0 -0.803866                 1.275711                 1.992254   \n",
       "\n",
       "         Fare  \n",
       "730 -0.388597  \n",
       "390 -0.484577  \n",
       "118 -0.042975  \n",
       "440 -0.388597  \n",
       "309  4.327664  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the data without Pclass and Sex columns\n",
    "scaler = StandardScaler()\n",
    "# Select numerical columns\n",
    "numerical_columns = ['Age', 'Siblings/Spouses Aboard','Parents/Children Aboard', 'Fare']\n",
    "# Scale the numerical columns\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Check the first 5 rows of the data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model/scaler.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler using joblib\n",
    "joblib.dump(scaler, 'Model/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Imbalanced Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalanced dataset\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81682028 1.28909091]\n"
     ]
    }
   ],
   "source": [
    "# Check class weights\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8168202764976958, 1: 1.289090909090909}\n"
     ]
    }
   ],
   "source": [
    "# Check class weights dictionary\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling TabNet with Weighted Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n"
     ]
    }
   ],
   "source": [
    "# Calculate n_steps for TabNet\n",
    "n_steps = X_train.shape[0] // 2\n",
    "# print n_steps\n",
    "print(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sparsemax Layer\n",
    "class Sparsemax(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tfa.activations.sparsemax(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TabNet Encoder\n",
    "class TabNetFeatureTransformer(keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(TabNetFeatureTransformer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dense1 = keras.layers.Dense(hidden_dim, activation='relu')\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.dense2 = keras.layers.Dense(hidden_dim, activation='relu')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "    # Add get_config method\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"hidden_dim\": self.hidden_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class TabNetAttentiveTransformer(keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(TabNetAttentiveTransformer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dense = keras.layers.Dense(hidden_dim)\n",
    "        self.sparsemax = Sparsemax()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = self.sparsemax(x)\n",
    "        return x\n",
    "\n",
    "    # Add get_config method\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"hidden_dim\": self.hidden_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class TabNetEncoder(keras.layers.Layer):\n",
    "    def __init__(self, feature_dim, num_steps):\n",
    "        super(TabNetEncoder, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.feature_transformer_shared = TabNetFeatureTransformer(feature_dim)\n",
    "        self.attentive_transformer = TabNetAttentiveTransformer(feature_dim)\n",
    "        self.masks = []  # Store masks for feature importance\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        masked_features = inputs\n",
    "        for step in range(self.num_steps):\n",
    "            # Feature transformer\n",
    "            transformed_features = self.feature_transformer_shared(masked_features)\n",
    "            \n",
    "            # Attentive transformer for feature selection\n",
    "            attention_weights = self.attentive_transformer(transformed_features)\n",
    "            masked_features = attention_weights * inputs\n",
    "            \n",
    "            self.masks.append(attention_weights)  # Save the mask\n",
    "            outputs.append(transformed_features)\n",
    "        \n",
    "        return keras.layers.Concatenate()(outputs)\n",
    "\n",
    "    # Add get_config method\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"feature_dim\": self.feature_dim,\n",
    "            \"num_steps\": self.num_steps,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabNet model\n",
    "def build_tabnet_model(input_shape, feature_dim, num_steps):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    tabnet_encoder = TabNetEncoder(feature_dim=feature_dim, num_steps=num_steps)(inputs)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(tabnet_encoder)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the TabNet model\n",
    "input_shape = X_train.shape[1]\n",
    "model = build_tabnet_model(input_shape=input_shape, feature_dim=6, num_steps=10)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " tab_net_encoder (TabNetEnco  (None, 60)               174       \n",
      " der)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 211\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks to monitor 'val_accuracy'\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),  # Stop early if no improvement\n",
    "    keras.callbacks.ModelCheckpoint('best_model_TabNet.h5', monitor='val_accuracy', save_best_only=True, verbose=1),  # Save the best model based on val_accuracy\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.0001, verbose=1)  # Reduce learning rate on plateau\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "708/709 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4703\n",
      "Epoch 1: val_accuracy improved from -inf to 0.38764, saving model to best_model_TabNet.h5\n",
      "709/709 [==============================] - 27s 30ms/step - loss: 0.6938 - accuracy: 0.4711 - val_loss: 28.5419 - val_accuracy: 0.3876 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "709/709 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5839\n",
      "Epoch 2: val_accuracy improved from 0.38764 to 0.56742, saving model to best_model_TabNet.h5\n",
      "709/709 [==============================] - 20s 29ms/step - loss: 0.6935 - accuracy: 0.5839 - val_loss: 24.5570 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "709/709 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.3907\n",
      "Epoch 3: val_accuracy did not improve from 0.56742\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6934 - accuracy: 0.3907 - val_loss: 23.6244 - val_accuracy: 0.5562 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "708/709 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.3884\n",
      "Epoch 4: val_accuracy improved from 0.56742 to 0.57303, saving model to best_model_TabNet.h5\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6933 - accuracy: 0.3893 - val_loss: 21.3549 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "709/709 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5219\n",
      "Epoch 5: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 29ms/step - loss: 0.6936 - accuracy: 0.5219 - val_loss: 24.0894 - val_accuracy: 0.3764 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "709/709 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4485\n",
      "Epoch 6: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6934 - accuracy: 0.4485 - val_loss: 22.3702 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "708/709 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.6158\n",
      "Epoch 7: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6933 - accuracy: 0.6150 - val_loss: 28.5679 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "709/709 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.4753\n",
      "Epoch 8: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6936 - accuracy: 0.4753 - val_loss: 20.8643 - val_accuracy: 0.3652 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "707/709 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4470\n",
      "Epoch 9: val_accuracy did not improve from 0.57303\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6934 - accuracy: 0.4471 - val_loss: 25.0223 - val_accuracy: 0.5393 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "708/709 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5876\n",
      "Epoch 10: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6933 - accuracy: 0.5867 - val_loss: 20.7518 - val_accuracy: 0.5562 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "709/709 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.6121\n",
      "Epoch 11: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6932 - accuracy: 0.6121 - val_loss: 24.1505 - val_accuracy: 0.5562 - lr: 2.0000e-04\n",
      "Epoch 12/100\n",
      "708/709 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5297\n",
      "Epoch 12: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6932 - accuracy: 0.5303 - val_loss: 24.2917 - val_accuracy: 0.5618 - lr: 2.0000e-04\n",
      "Epoch 13/100\n",
      "708/709 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5749\n",
      "Epoch 13: val_accuracy did not improve from 0.57303\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6932 - accuracy: 0.5740 - val_loss: 21.2533 - val_accuracy: 0.5506 - lr: 2.0000e-04\n",
      "Epoch 14/100\n",
      "707/709 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5007Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.57303\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "709/709 [==============================] - 20s 28ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 25.4158 - val_accuracy: 0.5562 - lr: 2.0000e-04\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model with class weights, callbacks, and verbose=2 for more detailed output\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=1, \n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights_dict,  # Handle imbalanced classes\n",
    "    callbacks=callbacks  # Add callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the trained model\n",
    "def get_tabnet_feature_importance(model, X):\n",
    "    # Get the feature transformer model\n",
    "    feature_transformer = model.get_layer('tab_net_encoder').feature_transformer_shared\n",
    "    # Get the weights of the feature transformer\n",
    "    feature_weights = feature_transformer.get_weights()[0]\n",
    "    # Calculate the importance of each feature\n",
    "    importance = np.abs(feature_weights).sum(axis=1)\n",
    "    # Normalize the importance\n",
    "    importance = importance / importance.max()\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = get_tabnet_feature_importance(model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names\n",
    "feature_names = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parents/Children Aboard</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.732656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.704009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.668670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.513875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Siblings/Spouses Aboard</td>\n",
       "      <td>0.418226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "4  Parents/Children Aboard    1.000000\n",
       "0                   Pclass    0.732656\n",
       "2                      Age    0.704009\n",
       "1                      Sex    0.668670\n",
       "5                     Fare    0.513875\n",
       "3  Siblings/Spouses Aboard    0.418226"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with feature names and importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the values in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "# Display the feature importance\n",
    "feature_importance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU",
   "language": "python",
   "name": "tensorflowgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
